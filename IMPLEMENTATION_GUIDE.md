# YVI EWS - Detailed Implementation Guide
## Step-by-Step Implementation for Critical Improvements

This guide provides detailed implementation steps for the highest-priority improvements that will scale your application to enterprise level.

---

## ðŸŽ¯ Priority 1: Redis Setup & Socket.IO Scaling

### Step 1: Install Dependencies

```bash
cd backend
npm install ioredis @socket.io/redis-adapter
```

### Step 2: Create Redis Configuration

**File: `backend/src/lib/redis.js`** (NEW FILE)

```javascript
const Redis = require('ioredis');
const config = require('@config');

const redisConfig = {
  host: process.env.REDIS_HOST || 'localhost',
  port: process.env.REDIS_PORT || 6379,
  password: process.env.REDIS_PASSWORD || undefined,
  retryStrategy: (times) => {
    const delay = Math.min(times * 50, 2000);
    return delay;
  },
  maxRetriesPerRequest: 3,
};

// Create Redis client
const redis = new Redis(redisConfig);

redis.on('connect', () => {
  console.log('âœ… Redis connected');
});

redis.on('error', (err) => {
  console.error('âŒ Redis connection error:', err);
});

module.exports = { redis, redisConfig };
```

### Step 3: Update Socket.IO with Redis Adapter

**File: `backend/src/server.js`** (MODIFY)

```javascript
require('dotenv').config();
require('module-alias/register');
const app = require('./app');
const config = require('@config');
const http = require('http');
const { Server } = require('socket.io');
const { createAdapter } = require('@socket.io/redis-adapter');
const { redis } = require('@lib/redis');

const PORT = process.env.PORT || config.PORT || 3003;

console.log('Attempting to start server...');

const server = http.createServer(app);
const io = new Server(server, {
    cors: {
        origin: config.NODE_ENV === 'production'
          ? [config.FRONTEND_URL, 'https://yviems.netlify.app']
          : [
              'http://localhost:8080',
              'http://localhost:8081',
              'http://localhost:8082',
              'http://localhost:5173',
              'http://127.0.0.1:8080',
              'http://127.0.0.1:8081',
              'http://127.0.0.1:8082',
              'http://127.0.0.1:5173'
            ],
        credentials: true
    },
    transports: ['websocket', 'polling'],
    adapter: createAdapter(redis, redis.duplicate())
});

// Initialize socket handlers
const SocketHandlers = require('./socketHandlers');
SocketHandlers.initialize(io);

server.listen(PORT, '0.0.0.0', () => {
    console.log(`Server is actually listening on port ${PORT}`);
    console.log(`Environment: ${config.NODE_ENV}`);
    console.log(`WebSocket server initialized with Redis adapter`);
});

// ... rest of the code remains the same
```

**Add to `.env`**:
```bash
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
```

---

## ðŸŽ¯ Priority 2: Redis Caching Layer

### Step 1: Create Cache Service

**File: `backend/src/services/cache.service.js`** (NEW FILE)

```javascript
const { redis } = require('@lib/redis');
const config = require('@config');

class CacheService {
  /**
   * Get value from cache
   */
  static async get(key) {
    try {
      const value = await redis.get(key);
      return value ? JSON.parse(value) : null;
    } catch (error) {
      console.error('Cache get error:', error);
      return null;
    }
  }

  /**
   * Set value in cache with TTL
   */
  static async set(key, value, ttlSeconds = 300) {
    try {
      await redis.setex(key, ttlSeconds, JSON.stringify(value));
      return true;
    } catch (error) {
      console.error('Cache set error:', error);
      return false;
    }
  }

  /**
   * Delete key from cache
   */
  static async delete(key) {
    try {
      await redis.del(key);
      return true;
    } catch (error) {
      console.error('Cache delete error:', error);
      return false;
    }
  }

  /**
   * Delete multiple keys matching pattern
   */
  static async deletePattern(pattern) {
    try {
      const keys = await redis.keys(pattern);
      if (keys.length > 0) {
        await redis.del(...keys);
      }
      return keys.length;
    } catch (error) {
      console.error('Cache delete pattern error:', error);
      return 0;
    }
  }

  /**
   * Invalidate cache for a specific entity type
   */
  static async invalidateEntity(entityType, entityId = null) {
    const patterns = [
      `${entityType}:${entityId || '*'}`,
      `${entityType}s:*`,
      `list:${entityType}s:*`
    ];
    
    for (const pattern of patterns) {
      await this.deletePattern(pattern);
    }
  }
}

module.exports = CacheService;
```

### Step 2: Create Cache Middleware

**File: `backend/src/middlewares/cache.middleware.js`** (NEW FILE)

```javascript
const CacheService = require('../services/cache.service');

/**
 * Cache middleware for GET requests
 */
const cacheMiddleware = (ttlSeconds = 300) => {
  return async (req, res, next) => {
    // Only cache GET requests
    if (req.method !== 'GET') {
      return next();
    }

    // Skip cache if query param noCache is present
    if (req.query.noCache === 'true') {
      return next();
    }

    // Generate cache key from URL and user context
    const userContext = req.user ? `:user:${req.user.id}` : '';
    const cacheKey = `cache:${req.originalUrl}${userContext}`;

    try {
      // Try to get from cache
      const cached = await CacheService.get(cacheKey);
      if (cached) {
        return res.status(200).json(cached);
      }

      // Store original json method
      const originalJson = res.json.bind(res);

      // Override json method to cache response
      res.json = function (data) {
        // Only cache successful responses
        if (res.statusCode === 200 && data.success !== false) {
          CacheService.set(cacheKey, data, ttlSeconds);
        }
        return originalJson(data);
      };

      next();
    } catch (error) {
      console.error('Cache middleware error:', error);
      next(); // Continue even if cache fails
    }
  };
};

module.exports = cacheMiddleware;
```

### Step 3: Use Cache in Controllers

**Example: `backend/src/controllers/employee.controller.js`** (MODIFY)

```javascript
const CacheService = require('../services/cache.service');

exports.getById = async (req, res, next) => {
    try {
        const { id } = req.params;
        const cacheKey = `employee:${id}`;

        // Try cache first
        const cached = await CacheService.get(cacheKey);
        if (cached) {
            return res.status(200).json({ success: true, data: cached, cached: true });
        }

        // Fetch from database
        const { data, error } = await supabase
            .from('employees')
            .select('*, department:departments!employees_department_id_fkey(*), manager:employees!employees_manager_id_fkey(*)')
            .eq('id', id)
            .single();

        if (error) throw error;
        if (!data) return res.status(404).json({ success: false, message: 'Employee not found' });

        const mappedData = mapEmployee(data);

        // Cache the result (5 minutes)
        await CacheService.set(cacheKey, mappedData, 300);

        res.status(200).json({ success: true, data: mappedData });
    } catch (err) {
        next(err);
    }
};

exports.create = async (req, res, next) => {
    try {
        // ... existing create logic ...

        // Invalidate cache after create
        await CacheService.invalidateEntity('employee');
        
        res.status(201).json({ success: true, data: mappedData });
    } catch (err) {
        next(err);
    }
};

exports.update = async (req, res, next) => {
    try {
        const { id } = req.params;
        // ... existing update logic ...

        // Invalidate specific employee cache
        await CacheService.delete(`employee:${id}`);
        await CacheService.invalidateEntity('employee');

        res.status(200).json({ success: true, data: mappedData });
    } catch (err) {
        next(err);
    }
};
```

---

## ðŸŽ¯ Priority 3: Real-Time Event Broadcasting

### Step 1: Create Event Emitter Service

**File: `backend/src/services/event.service.js`** (NEW FILE)

```javascript
class EventService {
  constructor(io) {
    this.io = io;
  }

  /**
   * Emit attendance update event
   */
  emitAttendanceUpdate(employeeId, attendanceData) {
    // Emit to employee
    this.io.to(`user:${attendanceData.userId}`).emit('attendance:updated', {
      employeeId,
      ...attendanceData
    });

    // Emit to department room
    if (attendanceData.departmentId) {
      this.io.to(`department:${attendanceData.departmentId}`).emit('attendance:updated', {
        employeeId,
        ...attendanceData
      });
    }

    // Emit to managers/admins
    this.io.to('role:ADMIN').to('role:HR').to('role:MANAGER').emit('attendance:updated', {
      employeeId,
      ...attendanceData
    });
  }

  /**
   * Emit leave status update
   */
  emitLeaveUpdate(leaveId, leaveData) {
    // Emit to employee
    this.io.to(`user:${leaveData.userId}`).emit('leave:updated', {
      leaveId,
      ...leaveData
    });

    // Emit to approvers
    if (leaveData.approverId) {
      this.io.to(`user:${leaveData.approverId}`).emit('leave:updated', {
        leaveId,
        ...leaveData
      });
    }

    // Emit to department managers
    if (leaveData.departmentId) {
      this.io.to(`department:${leaveData.departmentId}`).emit('leave:updated', {
        leaveId,
        ...leaveData
      });
    }
  }

  /**
   * Emit project update
   */
  emitProjectUpdate(projectId, projectData) {
    // Emit to project members
    this.io.to(`project:${projectId}`).emit('project:updated', {
      projectId,
      ...projectData
    });

    // Emit to project manager
    if (projectData.managerId) {
      this.io.to(`user:${projectData.managerId}`).emit('project:updated', {
        projectId,
        ...projectData
      });
    }
  }

  /**
   * Emit employee update
   */
  emitEmployeeUpdate(employeeId, employeeData) {
    // Emit to employee
    if (employeeData.userId) {
      this.io.to(`user:${employeeData.userId}`).emit('employee:updated', {
        employeeId,
        ...employeeData
      });
    }

    // Emit to department
    if (employeeData.departmentId) {
      this.io.to(`department:${employeeData.departmentId}`).emit('employee:updated', {
        employeeId,
        ...employeeData
      });
    }

    // Emit to admins/HR
    this.io.to('role:ADMIN').to('role:HR').emit('employee:updated', {
      employeeId,
      ...employeeData
    });
  }

  /**
   * Emit dashboard stats update
   */
  emitDashboardStats(role, userId, stats) {
    if (role === 'ADMIN') {
      this.io.to('role:ADMIN').emit('dashboard:stats', stats);
    } else if (role === 'HR') {
      this.io.to('role:HR').emit('dashboard:stats', stats);
    } else if (role === 'MANAGER') {
      this.io.to(`user:${userId}`).emit('dashboard:stats', stats);
    } else {
      this.io.to(`user:${userId}`).emit('dashboard:stats', stats);
    }
  }
}

module.exports = EventService;
```

### Step 2: Update Socket Handlers to Join Role Rooms

**File: `backend/src/socketHandlers.js`** (MODIFY)

```javascript
const { supabase, supabaseAdmin } = require('@lib/supabase');
const ChatService = require('./controllers/chat.service');

const activeUsers = new Map();
const userConversations = new Map();

class SocketHandlers {
  static initialize(io) {
    // Store io instance for event service
    this.io = io;
    
    // ... existing authentication middleware ...

    io.on('connection', (socket) => {
      console.log(`User ${socket.userId} connected via socket ${socket.id}`);

      activeUsers.set(socket.userId, socket.id);

      // Join user-specific room
      socket.join(`user:${socket.userId}`);

      // Join role-specific room
      socket.join(`role:${socket.user.role}`);

      // Join department room (if applicable)
      // This would require fetching employee's department
      // socket.join(`department:${departmentId}`);

      // ... rest of existing handlers ...
    });
  }

  // Make io accessible
  static getIO() {
    return this.io;
  }
}

module.exports = SocketHandlers;
```

### Step 3: Use Event Service in Controllers

**Example: `backend/src/controllers/attendance.controller.js`** (MODIFY)

```javascript
const SocketHandlers = require('../socketHandlers');
const EventService = require('../services/event.service');

// At the top of your create/update functions:
const createAttendance = async (req, res, next) => {
  try {
    // ... existing logic to create attendance ...

    // Emit real-time update
    const io = SocketHandlers.getIO();
    if (io) {
      const eventService = new EventService(io);
      eventService.emitAttendanceUpdate(data.id, {
        userId: employee.user_id,
        departmentId: employee.department_id,
        date: data.date,
        status: data.status,
        checkIn: data.check_in,
        checkOut: data.check_out
      });
    }

    res.status(201).json({ success: true, data });
  } catch (err) {
    next(err);
  }
};
```

---

## ðŸŽ¯ Priority 4: Database Indexes

### Step 1: Create Indexes SQL File

**File: `backend/database/indexes.sql`** (NEW FILE)

```sql
-- Performance indexes for YVI EWS

-- Employees table indexes
CREATE INDEX IF NOT EXISTS idx_employees_user_id ON employees(user_id);
CREATE INDEX IF NOT EXISTS idx_employees_department_id ON employees(department_id);
CREATE INDEX IF NOT EXISTS idx_employees_manager_id ON employees(manager_id);
CREATE INDEX IF NOT EXISTS idx_employees_status ON employees(status);
CREATE INDEX IF NOT EXISTS idx_employees_role ON employees(role);
CREATE INDEX IF NOT EXISTS idx_employees_email ON employees(email);
CREATE INDEX IF NOT EXISTS idx_employees_created_at ON employees(created_at DESC);

-- Attendance table indexes
CREATE INDEX IF NOT EXISTS idx_attendance_employee_id ON attendance(employee_id);
CREATE INDEX IF NOT EXISTS idx_attendance_date ON attendance(date DESC);
CREATE INDEX IF NOT EXISTS idx_attendance_employee_date ON attendance(employee_id, date DESC);
CREATE INDEX IF NOT EXISTS idx_attendance_status ON attendance(status);

-- Leaves table indexes
CREATE INDEX IF NOT EXISTS idx_leaves_employee_id ON leaves(employee_id);
CREATE INDEX IF NOT EXISTS idx_leaves_status ON leaves(status);
CREATE INDEX IF NOT EXISTS idx_leaves_approved_by ON leaves(approved_by);
CREATE INDEX IF NOT EXISTS idx_leaves_start_date ON leaves(start_date DESC);
CREATE INDEX IF NOT EXISTS idx_leaves_created_at ON leaves(created_at DESC);

-- Projects table indexes
CREATE INDEX IF NOT EXISTS idx_projects_manager_id ON projects(manager_id);
CREATE INDEX IF NOT EXISTS idx_projects_status ON projects(status);
CREATE INDEX IF NOT EXISTS idx_projects_created_at ON projects(created_at DESC);

-- Project members indexes
CREATE INDEX IF NOT EXISTS idx_project_members_project_id ON project_members(project_id);
CREATE INDEX IF NOT EXISTS idx_project_members_employee_id ON project_members(employee_id);

-- Chat indexes
CREATE INDEX IF NOT EXISTS idx_chat_conversations_user1_id ON chat_conversations(user1_id);
CREATE INDEX IF NOT EXISTS idx_chat_conversations_user2_id ON chat_conversations(user2_id);
CREATE INDEX IF NOT EXISTS idx_chat_messages_conversation_id ON chat_messages(conversation_id);
CREATE INDEX IF NOT EXISTS idx_chat_messages_created_at ON chat_messages(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_chat_messages_sender_id ON chat_messages(sender_id);
CREATE INDEX IF NOT EXISTS idx_chat_messages_receiver_id ON chat_messages(receiver_id);

-- Notifications indexes
CREATE INDEX IF NOT EXISTS idx_notifications_user_id ON notifications(user_id);
CREATE INDEX IF NOT EXISTS idx_notifications_read ON notifications(read);
CREATE INDEX IF NOT EXISTS idx_notifications_created_at ON notifications(created_at DESC);

-- Documents indexes
CREATE INDEX IF NOT EXISTS idx_documents_employee_id ON documents(employee_id);
CREATE INDEX IF NOT EXISTS idx_documents_created_at ON documents(created_at DESC);

-- Departments indexes
CREATE INDEX IF NOT EXISTS idx_departments_manager_id ON departments(manager_id);

-- Composite indexes for common queries
CREATE INDEX IF NOT EXISTS idx_attendance_employee_date_status ON attendance(employee_id, date DESC, status);
CREATE INDEX IF NOT EXISTS idx_leaves_employee_status ON leaves(employee_id, status);
CREATE INDEX IF NOT EXISTS idx_projects_manager_status ON projects(manager_id, status);
```

### Step 2: Run Indexes in Supabase

Execute this SQL file in your Supabase SQL Editor.

---

## ðŸŽ¯ Priority 5: Structured Logging

### Step 1: Install Dependencies

```bash
npm install winston winston-daily-rotate-file
```

### Step 2: Create Logger

**File: `backend/src/lib/logger.js`** (NEW FILE)

```javascript
const winston = require('winston');
const DailyRotateFile = require('winston-daily-rotate-file');
const path = require('path');

const logDir = 'logs';

const logFormat = winston.format.combine(
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
  winston.format.errors({ stack: true }),
  winston.format.splat(),
  winston.format.json()
);

const consoleFormat = winston.format.combine(
  winston.format.colorize(),
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
  winston.format.printf(({ timestamp, level, message, ...meta }) => {
    let msg = `${timestamp} [${level}]: ${message}`;
    if (Object.keys(meta).length > 0) {
      msg += ` ${JSON.stringify(meta)}`;
    }
    return msg;
  })
);

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: logFormat,
  defaultMeta: { service: 'yvi-ews' },
  transports: [
    // Error log file
    new DailyRotateFile({
      filename: path.join(logDir, 'error-%DATE%.log'),
      datePattern: 'YYYY-MM-DD',
      level: 'error',
      maxSize: '20m',
      maxFiles: '14d'
    }),
    // Combined log file
    new DailyRotateFile({
      filename: path.join(logDir, 'combined-%DATE%.log'),
      datePattern: 'YYYY-MM-DD',
      maxSize: '20m',
      maxFiles: '14d'
    })
  ]
});

// Add console transport for development
if (process.env.NODE_ENV !== 'production') {
  logger.add(new winston.transports.Console({
    format: consoleFormat
  }));
}

module.exports = logger;
```

### Step 3: Create Logging Middleware

**File: `backend/src/middlewares/logger.middleware.js`** (NEW FILE)

```javascript
const logger = require('../lib/logger');

const loggingMiddleware = (req, res, next) => {
  const start = Date.now();

  // Log request
  logger.info('Incoming request', {
    method: req.method,
    url: req.originalUrl,
    ip: req.ip,
    userAgent: req.get('user-agent'),
    userId: req.user?.id
  });

  // Override res.end to log response
  const originalEnd = res.end;
  res.end = function (chunk, encoding) {
    const duration = Date.now() - start;
    
    logger.info('Request completed', {
      method: req.method,
      url: req.originalUrl,
      statusCode: res.statusCode,
      duration: `${duration}ms`,
      userId: req.user?.id
    });

    originalEnd.call(this, chunk, encoding);
  };

  next();
};

module.exports = loggingMiddleware;
```

### Step 4: Use Logger in App

**File: `backend/src/app.js`** (MODIFY)

```javascript
const logger = require('./lib/logger');
const loggingMiddleware = require('./middlewares/logger.middleware');

// ... existing code ...

// Add logging middleware (before routes)
app.use(loggingMiddleware);

// ... rest of the code ...

// Error handler
app.use((err, req, res, next) => {
  logger.error('Unhandled error', {
    error: err.message,
    stack: err.stack,
    url: req.originalUrl,
    method: req.method,
    userId: req.user?.id
  });
  
  // ... existing error handling ...
});
```

---

## ðŸŽ¯ Priority 6: Frontend Optimization

### Step 1: Optimize Query Client

**File: `frontend/src/App.tsx`** (MODIFY)

```typescript
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      staleTime: 5 * 60 * 1000, // 5 minutes - data is fresh for 5 minutes
      cacheTime: 10 * 60 * 1000, // 10 minutes - cache persists for 10 minutes
      refetchOnWindowFocus: false, // Don't refetch on window focus
      refetchOnMount: false, // Don't refetch on mount if data exists
      retry: 1, // Retry failed requests once
      retryDelay: 1000, // Wait 1 second before retry
    },
    mutations: {
      retry: false, // Don't retry mutations
    },
  },
});

// ... rest of the code
```

### Step 2: Add Socket Listener for Data Updates

**File: `frontend/src/contexts/AuthContext.tsx`** (MODIFY)

```typescript
import { useQueryClient } from '@tanstack/react-query';
import { useEffect } from 'react';

// Inside AuthProvider component:
const queryClient = useQueryClient();

useEffect(() => {
  if (!user) return;

  // Listen for data update events
  const socket = chatService.getSocket(); // You'll need to expose socket
  if (socket) {
    socket.on('data:updated', (payload: { type: string; action: string }) => {
      // Invalidate relevant queries
      queryClient.invalidateQueries([payload.type]);
      
      // If it's a list, invalidate that too
      if (payload.type === 'employee') {
        queryClient.invalidateQueries(['employees']);
      }
      // ... add more as needed
    });

    return () => {
      socket.off('data:updated');
    };
  }
}, [user, queryClient]);
```

---

## âœ… Testing Checklist

After implementing each improvement:

- [ ] Test in development environment
- [ ] Verify no breaking changes
- [ ] Test with multiple concurrent users
- [ ] Monitor performance improvements
- [ ] Check logs for errors
- [ ] Test WebSocket connections
- [ ] Verify cache is working
- [ ] Test real-time updates

---

## ðŸš€ Deployment Checklist

Before deploying to production:

- [ ] Set up Redis server (cloud Redis recommended)
- [ ] Configure environment variables
- [ ] Run database indexes migration
- [ ] Set up log rotation
- [ ] Configure monitoring/alerting
- [ ] Test load with realistic data
- [ ] Set up backups for Redis
- [ ] Document configuration changes

---

*This guide provides the foundation for scaling your application. Implement these improvements incrementally and monitor the results.*


